{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPTもぐもぐ勉強会第2回\n",
        "毎週水曜19時~20時に、ChatGPTを、API含めて、Google ColabでもOpenAI上でも夕食でも食べながらもぐもぐ勉強できればと思います...！！！  \n",
        "\n"
      ],
      "metadata": {
        "id": "YKgBZdL8gG0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section0. GPT best practices - OpenAI API\n",
        "[GPT best practices](https://platform.openai.com/docs/guides/gpt-best-practices)  が提唱する戦略は、以下の6つ\n",
        "  \n",
        "\n",
        "*   明確な指示を書く\n",
        "*   参考テキストを提供する\n",
        "*   複雑なタスクをよりシンプルなサブタスクに分割する\n",
        "*   GPTに考える時間を与える\n",
        "*   外部ツールを利用する\n",
        "*   パフォーマンステストを実施する"
      ],
      "metadata": {
        "id": "PHpmnHSYDq_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section0-1. 明確な指示を書く\n",
        "関連性の高い答えを得るには、ユーザーは文章を入力する際に重要な情報を正しく提供する必要があります。例えば「大統領は誰ですか？」という質問よりも、「2021年のメキシコ大統領は誰ですか？選挙はどのくらいの頻度で行われますか？」という質問の方が、ユーザーの意図が明確にGPTへ伝わります。\n",
        "\n",
        "また、三重引用符やXMLタグなどの区切り文字を使うと、GPTが文字をどのように扱えばいいかが分かりやすくなります。例えば「論文を要約してタイトルを付けてください。タイトル：ここにタイトルを入力、要約：ここに要約を入力」といった質問のように、ユーザーの意図がどこにあり、GPTは答えをどのように出力すればいいのかを教えてあげることが大切。タスクが複雑であればあるほど、明確に指示することが重要になります。\n",
        "\n",
        "加えて、具体的な手順を指定することも役立つとのこと。例えば「ステップ1、ユーザーが三重引用符で囲った文章を提供するので、この文章に『概要：』という接頭辞を付けて一文にまとめてください」「ステップ2、ステップ1の概要をスペイン語に翻訳し、『翻訳：』という接頭辞を付けてください」といった感じの指示です。このほか、「約50語で要約してください」「3つの箇条書きで要約してください」など、具体的な数字を提示して指示するのも有効です"
      ],
      "metadata": {
        "id": "RjCMf2Nn9nei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section0-2. ChatGPT利用時の注意点\n",
        "\n",
        "\n",
        "*   **計算は、不得手**  \n",
        "ChatGPTは大規模言語モデル(LLM)であり、数値計算や論理演算のためのアルゴリズムを内包している、内蔵しているわけではないです。したがって、桁数の大きな四則演算も誤った回答をしますし、ましてや中高校生が学ぶような数学の問題も解くことはできません。\n",
        "*   **論理的な推論が、できない**  \n",
        "ChtaGPTと会話を繰り返していると、論理的な推論を行っているように一見するとみえますが、そうではありません。LLMとしての膨大な文章や言葉から最適と思われる\"つながり\"を組み立てて、あたかも論理的に推論しているかのように振る舞っているだけです。したがって、論理パズルのような質問に、全て答えることはできません。\n",
        "*   **回答が安全、とは限らない**  \n",
        "ChatGPTにおいて、GPT-3.5では犯罪に用いられるような危険な情報も含まれている(※[ウィズセキュア、ChatGPTのサイバー攻撃への悪用の可能性をリサーチ](https://prtimes.jp/main/html/rd/p/000000350.000001340.html))ようです。しかし、プロンプトでその情報を聞いても、ChatGPTは回答しないよう設計されているようです。ただし、プロンプトを工夫することによって、危険な情報を抽出することができてしまうこともあるため、プロンプト作成には十二分に気を付ける必要があります。\n",
        "*   **機密情報を入力、してはいけない**  \n",
        "入力したプロンプトの一部に、他のユーザーへの回答の参考や回答そのものに使われてしまうリスクがあります。もし機密情報を入力してしまうと、ChatGPTの学習データ経由で機密情報が流出してしまう可能性があります。社外秘や個人情報を入力することは危険ですので、十二分に気をつけてください。\n",
        "*   **検索エンジンの代替とは、ならない**  \n",
        "GPT-3.5においては、学習された情報、データが2021年までとなるため最新の情報を訪ねてもChatGPTは回答できません。\n",
        "\n"
      ],
      "metadata": {
        "id": "tyMFZPLXH6fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section1 openai を用いてGoogle ColaboratoryからChatGPTを利用する"
      ],
      "metadata": {
        "id": "nzOLcGW5Dri7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-1. 必要なライブラリをインストールする"
      ],
      "metadata": {
        "id": "WQBwDgdKD5eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# インストール\n",
        "!pip install langchain==0.0.218\n",
        "!pip install openai==0.27.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsNeaVvp0cnu",
        "outputId": "67bee4e1-c273-44fd-9611-d7d2b4a05f64"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.218\n",
            "  Downloading langchain-0.0.218-py3-none-any.whl (1.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.218)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.17 (from langchain==0.0.218)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.218)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.218) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.218) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.218) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.218) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.218) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.218) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.218) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.218)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.218)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.218) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.218) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.218) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.218) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.218) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.218) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.218)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langchainplus-sdk, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.218 langchainplus-sdk-0.0.20 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "Collecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 試してみる\n",
        "import openai\n",
        "\n",
        "# APIKey設定\n",
        "openai.api_key = \"sk-xxx\"\n",
        "\n",
        "# Prompt設定\n",
        "prompt = \"ChatGPTについて説明してください\"\n",
        "\n",
        "# 回答取得\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "# 結果表示\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFQgS5Hc1ilB",
        "outputId": "65f490d6-cc06-460c-9758-254fb0e29635"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ChatGPTは、AIチャットボット向けのプレーンテキスト自然言語処理（NLP）モデルです。チャットボットとやりとりするときの言葉を入力すると、その応答を返してくれます。ChatGPTは、機械翻訳や情報抽出等の多様なタスクで用いています。ChatGPTは、大規模なテキストコーパスを学習することで知識を得ており、その知識を用いて知的な会話を行うことができます。専門的な用語など、人間と会話する時にありがちな複雑な質問などにも素早く回答できます。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-2. ChatGPTで文章生成\n",
        "\n",
        "**モデル**  \n",
        "*   Davinci(davinci)  \n",
        "デフォルトでオススメされているエンジンです。複雑な文章生成などに向いています。\n",
        "*   Curie(curie)  \n",
        "より複雑な文章についてはDavinciの方が向いているようですが、Curieはセンチメント分析や翻訳などに向いているとのことです。\n",
        "*   Babbage(babage)  \n",
        "簡単なテキスト分類に向いています。\n",
        "*   Ada(ada)  \n",
        "一番速いモデルで単純な分類などに向いているとのことです。  "
      ],
      "metadata": {
        "id": "5yoQsbGfMlmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 文章生成\n",
        "#Prompt設定\n",
        "prompt = \"私のお気に入りのゲームはモンスターハンターで\"\n",
        "\n",
        "#回答取得\n",
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=100,\n",
        "    temperature=0.5,\n",
        "    echo=True\n",
        "    )"
      ],
      "metadata": {
        "id": "65UbGtHf08bx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVInNZpuTDzw",
        "outputId": "28ea62ce-0ec4-451b-e94b-15899947ed1d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7lYJcywhOl5BXyzcKvpC3cHrwsBUn at 0x7d3a882cc0e0> JSON: {\n",
              "  \"id\": \"cmpl-7lYJcywhOl5BXyzcKvpC3cHrwsBUn\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1691567680,\n",
              "  \"model\": \"davinci\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \"\\u79c1\\u306e\\u304a\\u6c17\\u306b\\u5165\\u308a\\u306e\\u30b2\\u30fc\\u30e0\\u306f\\u30e2\\u30f3\\u30b9\\u30bf\\u30fc\\u30cf\\u30f3\\u30bf\\u30fc\\u3067\\u3059\\u3002\\n\\n\\u30bb\\u30fc\\u30d6\\u30c7\\u30fc\\u30bf\\u3092\\u6d88\\u3057\\u3066\\u3057\\u307e\\u3063\\u305f\\u6642\\u306a\\u3093\\u304b\\u306f\\u3001\\u60b2\\u3057\\u3080\\u3053\\u3068\\u304c\\u591a\\u3044\\u3067\\u3059\\u3002\\n\\n\\u3051\\u308c\\u3069\\u3082\\u3001\\u79c1\\u306f\\u3053\\u306e\\u30b2\\u30fc\\u30e0\\u3092\\u3084\\u308a\\u305f\\u3044\\u3068\\u601d\\u3046\\u306e\\u3067\\u3001\\n\\n\\u30bb\\u30fc\\u30d6\\u30c7\\u30fc\\u30bf\\u3092\\u6d88\\u3057\\u3066\\u3082\\u3001\\u518d\\u5ea6\\u3084\\u308a\\u305f\\u3044\\u3068\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"length\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 28,\n",
              "    \"completion_tokens\": 100,\n",
              "    \"total_tokens\": 128\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPdOnf2CQTBt",
        "outputId": "f8a03930-7b52-414a-ec64-48d54d5ee63c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私のお気に入りのゲームはモンスターハンターです。\n",
            "\n",
            "セーブデータを消してしまった時なんかは、悲しむことが多いです。\n",
            "\n",
            "けれども、私はこのゲームをやりたいと思うので、\n",
            "\n",
            "セーブデータを消しても、再度やりたいと\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#回答取得その２\n",
        "response_2 = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=100,\n",
        "    temperature=0.5,\n",
        "    echo=True\n",
        "    )"
      ],
      "metadata": {
        "id": "FgWhM4IGTScd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_2['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhdMx9ZpTSfP",
        "outputId": "e7a616e0-2c84-42fa-de74-553cdc1853a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私のお気に入りのゲームはモンスターハンターです。\n",
            "\n",
            "I like your website and your blog. I am a game player. My favorite game is Monster Hunter.\n",
            "\n",
            "(僕はあなたのウェブサイトとブログが好きです。僕はゲームをプレイしています。私のお気に入りのゲームはモンスターハンターです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#回答取得その3\n",
        "response_3 = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=100,\n",
        "    temperature=0.5,\n",
        "    echo=True\n",
        "    )"
      ],
      "metadata": {
        "id": "HFLBK3SBTShe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_3['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bInqgNddTSkF",
        "outputId": "5c79b8fa-d574-4838-8d23-bc90cb65e6f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私のお気に入りのゲームはモンスターハンターです。特に最近のモンスターハンターは面白いです。\n",
            "\n",
            "――そんなモンスターハンターを今回のイベントに持ち込んでいるとは！ これは楽しみですね。\n",
            "\n",
            "羽根田：\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-3. パラメータあれこれ\n",
        "ここではよく使いそうなパラメータについて簡単に紹介したいと思います。  \n",
        "  \n",
        "*   prompt  \n",
        "インプットする文章です。これをどうデザインするかによってGPT-3がどんな文章を生成するか、意図通りの文章を生成するかが決まってきます。\n",
        "\n",
        "*   max_tokens  \n",
        "生成する文章の最大単語数です。\n",
        "\n",
        "*   temperature  \n",
        "0から2の範囲を取り、出力する単語のランダム性を指定します。0であれば完全に確定的な文章を出力するので、毎回同じ文章を生成します。センチメントの分類などでは0にする方がよいです。2であれば完全にランダムに次の単語、次の単語と選ぶので、意味の通らない文章になります。その中間を選ぶことで適度にランダムで意味の通った文章を生成することが可能です。\n",
        "\n",
        "*   top_p  \n",
        "これはtemperatureパラメータと相対するものです。top_pを0.1にすると、予測する次の単語は確率の高い上位10%の候補から選択されます。小さくすればするほど候補が確率の高いものに絞られるため、確定的になっていきます。大きくすれば色んな単語から選ぶようになるので、よりランダム性が強くなります。temperatureとtop_pはどちらかのみを選択します。\n",
        "\n",
        "*   echo  \n",
        "Trueにすることでpromptに入力されている文章も出力します。例えば、”My favourite XX is”といった文章をプロンプトに設定した場合に、続きの文章だけでなく”My favourite XX is …”という文章を返してくれます。\n",
        "\n",
        "*   stop  \n",
        "どんな単語が出現したら文章生成を打ち切るかを指定します。例えば改行”\\n”と指定すると改行された時点で文章生成が終了します。リストで渡すことで複数の単語を指定することができます。\n",
        "\n",
        "*   presence_penalty  \n",
        "-2.0から2.0の値を取り、既に出てきた単語をもう一度使うかどうかを指定します。-2.0に近いと同じ単語を繰り返し使うようになり、2.0に近いと同じ単語は繰り返し使いづらくなります。デフォルトはゼロです。\n",
        "\n",
        "*   frequency_penalty  \n",
        "こちらもpresence_penaltyと同じようなパラメータで-2.0から2.0の値を取り、出てきた回数が多いほどペナルティを大きくするものです。presence_penaltyと同様に-2.0に近いと同じ単語を繰り返し使うようになり、2.0に近いと同じ単語は繰り返し使わなくなります。presence_penaltyは1度でも使ったかどうか、ということにペナルティを加えますが、frequency_penaltyは使った回数に応じてペナルティを加えます。"
      ],
      "metadata": {
        "id": "acwwb2SDZIOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#　パラメータを変えてみる\n",
        "response_4 = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=500,\n",
        "    temperature=1.0,\n",
        "    echo=True\n",
        "    )"
      ],
      "metadata": {
        "id": "O8tJihSNTSmt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_4['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g86rt9QDTSpk",
        "outputId": "299e4e76-1b79-4807-c28a-aa97771c9d8a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私のお気に入りのゲームはモンスターハンターです ハンマー+ショックアロー+ブレイカーがワンハンド追加、いやワン盾だったかと思うが。 スコアだけのために撃つと思います。それで全てのレイド戦が大好きです。 そうです内部の会社が吉野家に上訴しました DLCに化ける3DS（大怪獣）Destiny Grimm Hunt EX in the Gardenです。 携帯電話版のMonster Hunter Portable 3rd HD ver.から寄贈を受け、無料開放やハンティングマンハント、獣耳アイコンを加えました。 hunterc5624Tantou Shinhsikiも最大装備で、ハンティングマンクロー出来ます。 【満足】全て月のDestiny Grimm Hunt EX in the Garden/Monster Hunter Portable 3rdの画像を再生して遊ぶ t.co/EbqGDvZ3Edハンターポータブル 3rd エクシード （PSP携帯）企業名：スパイク・チュンソフト株式会社E-mail：inquiry.sp@capcom.comURL記号：http://store.jp.square-enterprise.com/sp-playstation/sp/item/563/ハンターポータブル アクオラver. 発売時期：10月6日 日本最大級の検索サイト Destiy shinhsiki? 検索結果\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-4. プロンプトデザイン\n",
        "文章生成では、どんな文章でも生成できてしまうので、目的に合った文章を生成させるように質問（命令）しないといけません。  \n",
        "（プロンプトエンジニアリング）  "
      ],
      "metadata": {
        "id": "xzQUXo5hbFkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# センチメント分析\n",
        "prompt=\"This is a tweet sentiment classifier \\n\\nTweet: 'I love cat' \\nSentiment:'Positive' \\nTweet: 'I do not like tea' \\nSentiment:'Negative' \\nTweet: 'My day is good' \\nSentiment:'Positive' \\nTweet:'This is the link to website' \\nSentiment:'Neutral'\""
      ],
      "metadata": {
        "id": "ipqhtaWJTSss"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0RjEponywi",
        "outputId": "a13e36a0-7066-4512-dbe5-54c512e1a647"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a tweet sentiment classifier \n",
            "\n",
            "Tweet: 'I love cat' \n",
            "Sentiment:'Positive' \n",
            "Tweet: 'I do not like tea' \n",
            "Sentiment:'Negative' \n",
            "Tweet: 'My day is good' \n",
            "Sentiment:'Positive' \n",
            "Tweet:'This is the link to website' \n",
            "Sentiment:'Neutral'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt + \"\\nTweet:'This is a pen' \\nSentiment:\"\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-GcowhXn27h",
        "outputId": "592eb143-0e7a-4ea8-fb74-32df4ad18917"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a tweet sentiment classifier \n",
            "\n",
            "Tweet: 'I love cat' \n",
            "Sentiment:'Positive' \n",
            "Tweet: 'I do not like tea' \n",
            "Sentiment:'Negative' \n",
            "Tweet: 'My day is good' \n",
            "Sentiment:'Positive' \n",
            "Tweet:'This is the link to website' \n",
            "Sentiment:'Neutral'\n",
            "Tweet:'This is a pen' \n",
            "Sentiment:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# センチメント分析取得\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.0,\n",
        "  max_tokens=100,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.,\n",
        "  presence_penalty=0.,\n",
        "  stop=['\\n']\n",
        ")"
      ],
      "metadata": {
        "id": "POljqEOdmc5p"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUF8Q3BQoWMq",
        "outputId": "c124f07d-313b-4c06-c185-fdafb7241e88"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 'Neutral' \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "例を与えてあげることで、ChatGPT(今回はGPT-3.5)が何を答えればよいか？を理解することができます。\n",
        "\n",
        "この工夫（プロンプトエンジニアリング）によって何千・何万といった正解ラベルを与えずに、人間のようにいくつかの例示だけで解けるように\"誘導\"しています。([**`Few-shot learning`**](https://atmarkit.itmedia.co.jp/ait/articles/2308/03/news016.html))  \n",
        "\n",
        "  \n",
        "ここでは、temperatureパラメータを0.0としています。  \n",
        "分類問題ではtemperatureパラメータを小さくすることで、確定的な答え、または確定した答えを取得できるようにするべきです。temperatureパラメータが0.0よりも大きいと、ランダムに単語が選ばれるために、入力のたびに都度都度異なる答えが出力される、またpositive、negative, neutral以外の単語が出力されることになります。一方で文章生成などといったタスクにおいては、temperatureパラメータを大きくすることによって、\"人間\"っぽさを表現することが必要になります。  \n",
        "\n",
        "top_pパラメータでも同様です。\n",
        "その結果として、responseという変数の”text”というキーの中に、今回では”Neutral”と入っています。"
      ],
      "metadata": {
        "id": "PW_E0qicohOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ01Zux1qbSI",
        "outputId": "cf5c39b1-e138-4cb9-829b-d3a27dab5284"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7lZnWIMdpOn6VDlhxM2ZDiUOny7HB at 0x7d3a576d3920> JSON: {\n",
              "  \"id\": \"cmpl-7lZnWIMdpOn6VDlhxM2ZDiUOny7HB\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1691573378,\n",
              "  \"model\": \"davinci\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \" 'Neutral' \",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 94,\n",
              "    \"completion_tokens\": 5,\n",
              "    \"total_tokens\": 99\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでtemperatureは0.0に設定していますので、一番もっともらしい\"Neutral\"が常に返されます。\n",
        "そして、stop=[‘\\n’]とすることで”\\n”が出ると終了するようにしています"
      ],
      "metadata": {
        "id": "K1dEbuZwqeGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-5. 文章生成によるアイデアだし\n",
        "1つ目のアイデアを例示して、2つ目以降をChatGPT(GPT-3.5)に生成してもらいましょう。"
      ],
      "metadata": {
        "id": "dIuKxVUyqv2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"教育と仮想現実に関するアイデア \\n\\n1.仮想的な火星。 \\n学生は仮想的に火星探索を行うことで火星の地質や天候その他火星に関する情報を擬似的に学習することができる。 \\n\\n2.\"\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4qWYewNqvU7",
        "outputId": "9e4b8acc-91f3-48af-b14d-6fa1ada0c228"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "教育と仮想現実に関するアイデア \n",
            "\n",
            "1.仮想的な火星。 \n",
            "学生は仮想的に火星探索を行うことで火星の地質や天候その他火星に関する情報を擬似的に学習することができる。 \n",
            "\n",
            "2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.5,\n",
        "  max_tokens=300,\n",
        "  #top_p=1,\n",
        "  frequency_penalty=0.,\n",
        "  presence_penalty=0.,\n",
        ")"
      ],
      "metadata": {
        "id": "_UHixaqctEsb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWPMgMMdtTBi",
        "outputId": "376b89d8-13ae-443e-db70-0600bee9b0b4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "仮想的な月面。 仮想的に月面を探索することで月面の地質や天候その他月面に関する情報を擬似的に学習することができる。 \n",
            "\n",
            "3.仮想的な深海。 仮想的に深海を探索することで深海の地質や天候その他深海に関する情報を擬似的に学習することができる。 \n",
            "\n",
            "4.仮想的な宇宙。 仮想的に宇宙を探索することで宇宙の地質や天候その他宇宙に関する情報を擬似的に学習することができる。 \n",
            "\n",
            "5.仮想\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section2. チャットぼっと"
      ],
      "metadata": {
        "id": "wPRpWwwfkSrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "class Chatbot:\n",
        "  # お金かからない、gpt-3.5-turboで試す(デフォルト指定)\n",
        "  def __init__(self, model=\"gpt-3.5-turbo\", messages=None, temperature=0, stream=True):\n",
        "    self.model = model  # \"gpt-4\" or \"gpt-4-32k\" or \"gpt-3.5-turbo\"\n",
        "    self.messages = messages or []\n",
        "    self.temperature = temperature\n",
        "    self.stream = stream\n",
        "\n",
        "  def chat(self, prompt, temperature=None, stream=None):\n",
        "    prompt = prompt.strip()\n",
        "    self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    stream = stream or self.stream\n",
        "    response = openai.ChatCompletion.create(model=self.model,\n",
        "                                       messages=self.messages,\n",
        "                                       temperature=temperature or self.temperature,\n",
        "                                       stream=stream)\n",
        "    if stream:\n",
        "        answer = []\n",
        "        for chunk in response:\n",
        "            content = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "            print(content, end=\"\")\n",
        "            answer.append(content)\n",
        "        answer = \"\".join(answer).strip()\n",
        "    else:\n",
        "        answer = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "        print(answer)\n",
        "        usage = response[\"usage\"]\n",
        "        print(usage[\"prompt_tokens\"], usage[\"completion_tokens\"], usage[\"total_tokens\"])\n",
        "    self.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "  def get_messages(self):\n",
        "    return self.messages"
      ],
      "metadata": {
        "id": "kKMhJldoklgj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = Chatbot()\n",
        "chatbot.chat(\"こんにちは！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtb2ldRrk4_0",
        "outputId": "8ecd50a9-a36f-4867-ebff-685e561ca160"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "こんにちは！どのようにお手伝いできますか？"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.chat(\"なんとお呼びすればいいでしょうか？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaAt7naplIVc",
        "outputId": "af998cbe-1468-40ee-a4a4-b4315110687d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私はAIアシスタントですので、特にお呼びする名前はありません。ただし、お好きな名前で呼んでいただいても構いません。どのようにお呼びしましょうか？"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.chat(\"それでは、'AIちゃん'と呼びますね！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsoHYEzBlVTK",
        "outputId": "f3cc0e97-8721-488f-faf5-7375788d475d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "かしこまりました！'AIちゃん'と呼んでいただければとても嬉しいです。どのようなお手伝いをさせていただけますか？"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.chat(\"喜んでくれて、ありがとう！まずは、自己紹介してください！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hplj7JMOlhJ4",
        "outputId": "62ed5c6d-4877-4b43-f471-4e68083abc08"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "もちろんです！私はAIちゃんと呼ばれることができるAIアシスタントです。自然言語処理や機械学習の技術を使って、さまざまな情報や質問に対してお手伝いすることができます。翻訳、時計、天気予報、ニュース、エンターテイメント、一般的な知識など、さまざまなトピックについてお答えできます。どのようなお手伝いをお探しですか？"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.get_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUXphfU8luiA",
        "outputId": "8caa0e67-b1e9-4fb3-9d6a-580cca703398"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user', 'content': 'こんにちは！'},\n",
              " {'role': 'assistant', 'content': 'こんにちは！どのようにお手伝いできますか？'},\n",
              " {'role': 'user', 'content': 'なんとお呼びすればいいでしょうか？'},\n",
              " {'role': 'assistant',\n",
              "  'content': '私はAIアシスタントですので、特にお呼びする名前はありません。ただし、お好きな名前で呼んでいただいても構いません。どのようにお呼びしましょうか？'},\n",
              " {'role': 'user', 'content': \"それでは、'AIちゃん'と呼びますね！\"},\n",
              " {'role': 'assistant',\n",
              "  'content': \"かしこまりました！'AIちゃん'と呼んでいただければとても嬉しいです。どのようなお手伝いをさせていただけますか？\"},\n",
              " {'role': 'user', 'content': '喜んでくれて、ありがとう！まずは、自己紹介してください！'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'もちろんです！私はAIちゃんと呼ばれることができるAIアシスタントです。自然言語処理や機械学習の技術を使って、さまざまな情報や質問に対してお手伝いすることができます。翻訳、時計、天気予報、ニュース、エンターテイメント、一般的な知識など、さまざまなトピックについてお答えできます。どのようなお手伝いをお探しですか？'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}