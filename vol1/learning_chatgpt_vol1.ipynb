{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPTもぐもぐ勉強会第1回\n",
        "毎週水曜19時~20時に、ChatGPTを、API含めて、Google ColabでもOpenAI上でも夕食でも食べながらもぐもぐ勉強できればと思います...！！！  \n",
        "\n"
      ],
      "metadata": {
        "id": "YKgBZdL8gG0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section1. GPT best practices - OpenAI API\n",
        "[GPT best practices](https://platform.openai.com/docs/guides/gpt-best-practices)  が提唱する戦略は、以下の6つ\n",
        "  \n",
        "\n",
        "*   明確な指示を書く\n",
        "*   参考テキストを提供する\n",
        "*   複雑なタスクをよりシンプルなサブタスクに分割する\n",
        "*   GPTに考える時間を与える\n",
        "*   外部ツールを利用する\n",
        "*   パフォーマンステストを実施する"
      ],
      "metadata": {
        "id": "PHpmnHSYDq_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-1. 明確な指示を書く\n",
        "関連性の高い答えを得るには、ユーザーは文章を入力する際に重要な情報を正しく提供する必要があります。例えば「大統領は誰ですか？」という質問よりも、「2021年のメキシコ大統領は誰ですか？選挙はどのくらいの頻度で行われますか？」という質問の方が、ユーザーの意図が明確にGPTへ伝わります。\n",
        "\n",
        "また、三重引用符やXMLタグなどの区切り文字を使うと、GPTが文字をどのように扱えばいいかが分かりやすくなります。例えば「論文を要約してタイトルを付けてください。タイトル：ここにタイトルを入力、要約：ここに要約を入力」といった質問のように、ユーザーの意図がどこにあり、GPTは答えをどのように出力すればいいのかを教えてあげることが大切。タスクが複雑であればあるほど、明確に指示することが重要になります。\n",
        "\n",
        "加えて、具体的な手順を指定することも役立つとのこと。例えば「ステップ1、ユーザーが三重引用符で囲った文章を提供するので、この文章に『概要：』という接頭辞を付けて一文にまとめてください」「ステップ2、ステップ1の概要をスペイン語に翻訳し、『翻訳：』という接頭辞を付けてください」といった感じの指示です。このほか、「約50語で要約してください」「3つの箇条書きで要約してください」など、具体的な数字を提示して指示するのも有効です"
      ],
      "metadata": {
        "id": "WBkVi1aeD5Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-2. 参考テキストを提供する\n",
        "「次に示す論文に記載された文章だけを使って質問に答えてください」といったように、体系的な情報をGPTに提供できれば、GPTは提供された情報を使って答えを構成するよう試みるとのこと。ただし、GPTへ一度に与えられる文章の文字数は限られているため、OpenAIが提供する「埋め込み」[Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)と呼ばれる関連性検索システムを使うことが推奨されています。"
      ],
      "metadata": {
        "id": "LGj7AbWQEKaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Section1-2-1. 「埋め込み」Embeddings\n",
        "OpenAI のテキスト埋め込みは、テキスト文字列の関連性を測定します。埋め込みは一般的に次の目的で使用されます。\n",
        "\n",
        "*   検索(クエリ文字列との関連性によって結果がランク付けされます)\n",
        "*   クラスタリング(テキスト文字列が類似性によってグループ化される)\n",
        "*   推奨事項(関連するテキスト文字列を持つアイテムが推奨される場合)\n",
        "*   異常検出（関連性の低い外れ値が特定される場合）\n",
        "*   多様性測定（類似性分布を分析する場合）\n",
        "*   分類(テキスト文字列が最も類似したラベルによって分類されます)\n",
        "\n",
        "埋め込みは、浮動小数点数のベクトル (リスト) です。2 つのベクトル間の距離によって、それらの関連性が測定されます。距離が小さい場合は関連性が高いことを示し、距離が大きい場合は関連性が低いことを示します。\n",
        "\n",
        "埋め込みの料金については、[料金ページ](https://openai.com/pricing)にアクセスしてください。  \n",
        "[リクエストは、送信された](https://platform.openai.com/docs/api-reference/embeddings/create#embeddings/create-input)入力内の[トークン](https://platform.openai.com/tokenizer)の数に基づいて課金されます。\n"
      ],
      "metadata": {
        "id": "KSwpQ6CWEfzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Section1-2-2. 埋め込みの作成\n",
        "```\n",
        "POST https://api.openai.com/v1/embeddings\n",
        "```\n",
        "入力テキストを表す埋め込みベクトルを作成します。\n",
        "\n",
        "```\n",
        "curl https://api.openai.com/v1/embeddings \\\n",
        "  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\n",
        "    \"input\": \"The food was delicious and the waiter...\",\n",
        "    \"model\": \"text-embedding-ada-002\"\n",
        "  }'\n",
        "```\n",
        "**Request body**  \n",
        "\n",
        "*   `model` string型（文字型）  \n",
        "使用するモデルのID。[List models](https://platform.openai.com/docs/api-reference/models/list) APIを使用して、利用可能なすべてのモデルを確認したり、モデルの説明については[モデル](https://platform.openai.com/docs/models/overview)の概要を参照したりできます。 OpenAI API は、さまざまな機能と価格帯を備えたさまざまなモデルのセットを利用しています。また、微調整を行うことで、特定のユースケースに合わせてオリジナルのベース モデルを限定的にカスタマイズすることもできます。\n",
        "\n",
        "| MODELS | DESCRIPTION |\n",
        "| ---- | ---- |\n",
        "| GPT-4 | GPT-3.5 を改良し、自然言語やコードを理解し、生成できるモデル |\n",
        "| GPT-3.5 | GPT-3 を改良し、自然言語やコードを理解し、生成できるモデル |\n",
        "| DALL·E | 自然言語プロンプトが与えられた場合に画像を生成および編集できるモデル |\n",
        "| Whisper | 音声をテキストに変換できるモデル |\n",
        "| Embeddings | テキストを数値形式に変換できるモデル |\n",
        "| Moderation | テキストが機密性の高いものであるか、または安全でない可能性があるかを検出できる、微調整されたモデル |\n",
        "| GPT-3Legacy | 自然言語を理解して生成できる一連のモデル |\n",
        "| Deprecated | 廃止されたモデルのリスト |\n",
        "\n",
        "*   `input` string型（文字型） または 配列型  \n",
        "\n",
        "埋め込むテキストを入力し、文字列またはトークンの配列としてエンコードします。 1 つのリクエストに複数の入力を埋め込むには、文字列の配列またはトークン配列の配列を渡します。各入力は、モデルの最大入力トークン (text-embedding-ada-002 の場合は 8191 トークン) を超えてはなりません。\n",
        "\n"
      ],
      "metadata": {
        "id": "u_xsDvcBLW0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Section1-2-3. 埋め込みサンプル例\n",
        "この例で使用されるデータセットは、Amazon の高級食品のレビューです。このデータセットには、Amazon ユーザーが 2012 年 10 月までに残した合計 568,454 件の食品レビューが含まれています。説明のために、最新の 1,000 件のレビューで構成されるこのデータセットのサブセットを使用します。レビューは英語で書かれており、肯定的または否定的な傾向があります。各レビューには、ProductId、UserId、スコア、レビュー タイトル (概要)、レビュー本文 (テキスト) があります。\n",
        "\n",
        "レビュー概要とレビュー本文を 1 つの結合テキストに結合します。モデルはこの結合されたテキストをエンコードし、単一のベクトル埋め込みを出力します。\n",
        "\n",
        "このノートブックを実行するには、pandas、openai、transformers、plotly、matplotlib、scikit-learn、torch (transformer dep)、torchvision、および scipy をインストールする必要があります。"
      ],
      "metadata": {
        "id": "t9Hfnpb3YPQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44SuyjKTYraL",
        "outputId": "2610c47a-e772-4e19-cac2-efdcdfe629f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.5/1.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PA3hMTtY6V9",
        "outputId": "535edf37-05f3-4572-d38d-5ba2d979def6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "\n",
        "from openai.embeddings_utils import get_embedding"
      ],
      "metadata": {
        "id": "0qrqVTylYN3X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルパラメータの埋め込み\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "embedding_encoding = \"cl100k_base\"  # text-embedding-ada-002 のエンコーディング\n",
        "max_tokens = 8000  # text-embedding-ada-002 の最大値は 8191 です"
      ],
      "metadata": {
        "id": "i9fz0YzJX9BV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットのロードと検査\n",
        "input_datapath = \"fine_food_reviews_1k.csv\"  # スペースを節約するために、事前にフィルタリングされたデータセットを提供\n",
        "df = pd.read_csv(input_datapath, index_col=0)\n",
        "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
        "df = df.dropna()\n",
        "df[\"combined\"] = (\n",
        "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
        ")\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "E4_ndB3VX9P_",
        "outputId": "5bd92f7b-d7f2-47a1-d2af-00361bbfa248"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Time   ProductId          UserId  Score  \\\n",
              "0  1351123200  B003XPF9BO  A3R7JR3FMEBXQB      5   \n",
              "1  1351123200  B003JK537S  A3JBPC3WFUT5ZP      1   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  where does one  start...and stop... with a tre...   \n",
              "1                                  Arrived in pieces   \n",
              "\n",
              "                                                Text  \\\n",
              "0  Wanted to save some to bring to my Chicago fam...   \n",
              "1  Not pleased at all. When I opened the box, mos...   \n",
              "\n",
              "                                            combined  \n",
              "0  Title: where does one  start...and stop... wit...  \n",
              "1  Title: Arrived in pieces; Content: Not pleased...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b071090d-9c71-44bb-86a1-0c35c660de36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Score</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1351123200</td>\n",
              "      <td>B003XPF9BO</td>\n",
              "      <td>A3R7JR3FMEBXQB</td>\n",
              "      <td>5</td>\n",
              "      <td>where does one  start...and stop... with a tre...</td>\n",
              "      <td>Wanted to save some to bring to my Chicago fam...</td>\n",
              "      <td>Title: where does one  start...and stop... wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1351123200</td>\n",
              "      <td>B003JK537S</td>\n",
              "      <td>A3JBPC3WFUT5ZP</td>\n",
              "      <td>1</td>\n",
              "      <td>Arrived in pieces</td>\n",
              "      <td>Not pleased at all. When I opened the box, mos...</td>\n",
              "      <td>Title: Arrived in pieces; Content: Not pleased...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b071090d-9c71-44bb-86a1-0c35c660de36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-92dd5847-e948-4816-9491-1dbc758740da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92dd5847-e948-4816-9491-1dbc758740da')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-92dd5847-e948-4816-9491-1dbc758740da button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b071090d-9c71-44bb-86a1-0c35c660de36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b071090d-9c71-44bb-86a1-0c35c660de36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 最新の 1,000 件のレビューをサブサンプリングし、長すぎるサンプルを削除\n",
        "top_n = 1000\n",
        "df = df.sort_values(\"Time\").tail(top_n * 2)  # 最初は最初の 2,000 エントリに切り分けられ、半分未満がフィルタで除外されると仮定\n",
        "df.drop(\"Time\", axis=1, inplace=True)\n",
        "\n",
        "encoding = tiktoken.get_encoding(embedding_encoding)\n",
        "\n",
        "# 埋め込むには長すぎるレビューを省略する\n",
        "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
        "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRD26EWGX9SH",
        "outputId": "0b8e6172-bd9a-417e-c519-95575cc19e43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# README に従って API キーが環境に設定されていることを確認してください: https://github.com/openai/openai-python#usage"
      ],
      "metadata": {
        "id": "unYZf4jJapbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ライブラリは、[API keys](https://platform.openai.com/account/api-keys)で入手できるアカウントの秘密キーを使用して構成する必要があります。ライブラリを使用する前に、これを OPENAI_API_KEY 環境変数として設定します。(下のイメージのところから、API KEYを作成します)\n",
        "\n",
        "![任意の画像名を付ける](https://drive.google.com/uc?id=1Cf1rAX42SuS9zKrK8j8rfAkbXBdFnKQv)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "export OPENAI_API_KEY='sk-...'\n",
        "```\n",
        "\n",
        "または、`openai.api_key` をその値に設定します。\n",
        "  \n",
        "```\n",
        "import openai\n",
        "openai.api_key = \"sk-...\"\n",
        "\n",
        "# list models\n",
        "models = openai.Model.list()\n",
        "\n",
        "# print the first model's id\n",
        "print(models.data[0].id)\n",
        "\n",
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\n",
        "\n",
        "# print the chat completion\n",
        "print(chat_completion.choices[0].message.content)\n",
        "```"
      ],
      "metadata": {
        "id": "b4zFEI80aq_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddingの処理、数分程度\n",
        "df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, engine=embedding_model))\n",
        "df.to_csv(\"fine_food_reviews_with_embeddings_1k.csv\")"
      ],
      "metadata": {
        "id": "WDfa0RhWasDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-3. 複雑なタスクをよりシンプルなサブタスクに分割する\n",
        "ユーザーが放つ曖昧かつ複雑な質問をそのままGPTに受け取らせるのではなく、質問を分割してGPTへ伝えることで、エラー率を低く抑えることが可能。例えば「インターネットを再び使えるようにしたい」という質問を受けた場合、「ケーブルはつながっている？再起動は試した」などの答えを順番に出力するよう教えることで、問題を段階的に解決していくことができます。"
      ],
      "metadata": {
        "id": "7TWiRce-EjBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-4. GPTに考える時間を与える\n",
        "GPTに「とある課題について、学生からこんな回答がありました。これは正しいですか？」と聞くよりも、「学生からこんな回答がありました。あなた自身の答えを考えてから、学生の答えが正しいかどうかを判断してください」といったように、GPTに考える時間を与えた方がミスが少なくなるとのこと。"
      ],
      "metadata": {
        "id": "eBqnX80_h1PV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-5. 外部ツールを利用する\n",
        "GPTだけでは長い文章や計算式を処理しきれないため、前述の「埋め込み」や外部サービスのAPIを使って答えを出力させることも効果的です。"
      ],
      "metadata": {
        "id": "j22FR6oah-Ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section1-6. パフォーマンステストを実施する\n",
        "既存の質問で望み通りの回答を得られている状態で、さらに新たな質問を追加した場合、その質問をしたことで既存の回答品質が低下してしまう可能性が考えられます。こうした変更がシステムを良くするのか悪くするのかを見分けるのが難しい場合、[OpenAI Evals](https://github.com/openai/evals)などの評価ツールを使い、効果的な質問のバリエーションを検討することができます。"
      ],
      "metadata": {
        "id": "ssDJT82Fh-NB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Section1-6-1. OpenAI Evalsとは\n",
        "Evals は、LLM (大規模言語モデル)、または LLM をコンポーネントとして使用して構築されたシステムを評価するためのフレームワークです。また、eval のオープンソース レジストリも含まれています。プロンプト チェーンやツールを使用するエージェントを含むあらゆるシステムの動作の評価を、[Completion Function Protocol](https://github.com/openai/evals/blob/main/docs/completion-fns.md) でサポートされています。  \n",
        "  \n",
        "Eval では、できる限り少ないコードを記述しながら、できる限り簡単に eval を構築できるようにすることを目指しています。 「eval」は、システムの動作の品質を評価するために使用されるタスクです。開始するには、次の手順に従うことをお勧めします。\n",
        "\n",
        "evals を設定するには、以下の設定手順に従ってください。  \n",
        "\n",
        "*   Setup  \n",
        "eval を実行するには、OpenAI API キーを設定して指定する必要があります。 https://platform.openai.com/account/api-keys で生成できます。 API キーを取得したら、OPENAI_API_KEY 環境変数を使用して API キーを指定します。評価を実行するときは、API の使用に関連するコストに注意してください。\n",
        "最低限必要なバージョン: Python 3.9\n",
        "\n",
        "*   Downloading evals\n",
        "Evals レジストリは [Git-LFS](https://git-lfs.com/) を使用して保存されます。 LFS をダウンロードしてインストールしたら、次のコマンドを使用して (evals リポジトリのローカル コピー内から) eval をfetchできます。\n",
        "```\n",
        "cd evals\n",
        "git lfs fetch --all\n",
        "git lfs pull\n",
        "```\n",
        "これにより、 `evals/registry/data` の下にある、すべてのポインターファイルが設定されます。選択評価のためのデータをfetchしたいだけの場合は、次の方法で実現できます。\n",
        "```\n",
        "git lfs fetch --include=evals/registry/data/${your eval}\n",
        "git lfs pull\n",
        "```\n",
        "*   Making evals  \n",
        "eval を作成する場合は、このリポジトリを GitHub から直接複製し、次のコマンドを使用して要件をインストールすることをお勧めします。\n",
        "```\n",
        "pip install -e .\n",
        "```\n",
        "`-e` を使用すると、eval に加えた変更は再インストールすることなくすぐに反映されます。\n",
        "オプションで、次の方法で事前コミット用のフォーマッタをインストールできます。\n",
        "```\n",
        "pip install -e .[formatters]\n",
        "```\n",
        "*    Running evals\n",
        "新しい eval を提供したくないが、単にローカルで実行したい場合は、pip 経由で eval パッケージをインストールできます。\n",
        "```\n",
        "pip install evals\n",
        "```\n",
        "Snowflake データベースをお持ちの場合、または設定したい場合には、評価結果を Snowflake データベースに記録するオプションを提供します。このオプションでは、さらに `SNOWFLAKE_ACCOUNT`、`SNOWFLAKE_DATABASE`、`SNOWFLAKE_USERNAME`、および `SNOWFLAKE_PASSWORD` 環境変数を指定する必要があります。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "glsDMKcWh-Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Section1-6-2. OpenAI Evals を試してみる\n"
      ],
      "metadata": {
        "id": "qSoXbdsyqCjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# リポジトリのクローン\n",
        "# クローン\n",
        "!git clone https://github.com/openai/evals.git\n",
        "!cd ./evals\n",
        "\n",
        "# Git LFSからコードを取得\n",
        "!git lfs fetch --all\n",
        "!git lfs pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euWOP7JCqcxd",
        "outputId": "10986ef9-9434-4c44-8544-76cf1b94e24a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'evals'...\n",
            "remote: Enumerating objects: 5680, done.\u001b[K\n",
            "remote: Counting objects: 100% (1328/1328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 5680 (delta 1231), reused 1171 (delta 1168), pack-reused 4352\u001b[K\n",
            "Receiving objects: 100% (5680/5680), 2.70 MiB | 6.94 MiB/s, done.\n",
            "Resolving deltas: 100% (2961/2961), done.\n",
            "Filtering content: 100% (536/536), 561.43 MiB | 28.47 MiB/s, done.\n",
            "Not in a git repository.\n",
            "Not in a git repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcLHuTzBtsQk",
        "outputId": "c4b312ad-0436-46e9-f7d5-812360f9b683"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build) (23.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxTMr7aqvcww",
        "outputId": "c9811632-5679-45ed-a764-7085c63edbef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evals  fine_food_reviews_1k.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd evals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sFAjJRDv4Tp",
        "outputId": "39258733-68dc-41a1-e729-830194a98d56"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/evals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E59xPkY4v7ox",
        "outputId": "68cee3d4-62c1-4250-cb8b-6b225ad4f718"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 56\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:29 docs\n",
            "drwxr-xr-x 8 root root 4096 Aug  4 08:29 evals\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:29 examples\n",
            "-rw-r--r-- 1 root root 1063 Aug  4 08:29 LICENSE\n",
            "-rw-r--r-- 1 root root   68 Aug  4 08:29 Makefile\n",
            "-rw-r--r-- 1 root root  136 Aug  4 08:29 MANIFEST.in\n",
            "-rw-r--r-- 1 root root 1014 Aug  4 08:29 mypy.ini\n",
            "-rw-r--r-- 1 root root  751 Aug  4 08:29 pyproject.toml\n",
            "-rw-r--r-- 1 root root 5704 Aug  4 08:29 README.md\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:29 scripts\n",
            "-rw-r--r-- 1 root root  413 Aug  4 08:29 SECURITY.md\n",
            "drwxr-xr-x 3 root root 4096 Aug  4 08:29 tests\n",
            "drwxr-xr-x 3 root root 4096 Aug  4 08:29 typings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pyproject.toml　があるディレクトリ配下で下記コマンド実行\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7F5U58LlwFXN",
        "outputId": "7907f08f-255d-4a8f-f3e6-89ff3da377ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/evals\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mypy (from evals==1.0.3.post1)\n",
            "  Downloading mypy-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (0.27.8)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (0.4.0)\n",
            "Collecting blobfile (from evals==1.0.3.post1)\n",
            "  Downloading blobfile-2.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from evals==1.0.3.post1)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (1.22.4)\n",
            "Collecting snowflake-connector-python[pandas] (from evals==1.0.3.post1)\n",
            "  Downloading snowflake_connector_python-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (1.5.3)\n",
            "Collecting datasets (from evals==1.0.3.post1)\n",
            "  Downloading datasets-2.14.3-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from evals==1.0.3.post1)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (1.10.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (4.65.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (3.12.2)\n",
            "Collecting mock (from evals==1.0.3.post1)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Collecting langdetect (from evals==1.0.3.post1)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (2.3.0)\n",
            "Collecting lz4 (from evals==1.0.3.post1)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd (from evals==1.0.3.post1)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (6.0.1)\n",
            "Collecting sacrebleu (from evals==1.0.3.post1)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (3.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (7.2.2)\n",
            "Collecting setuptools-scm (from evals==1.0.3.post1)\n",
            "  Downloading setuptools_scm-7.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain (from evals==1.0.3.post1)\n",
            "  Downloading langchain-0.0.251-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-PyYAML (from evals==1.0.3.post1)\n",
            "  Downloading types_PyYAML-6.0.12.11-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.2->evals==1.0.3.post1) (2.27.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.2->evals==1.0.3.post1) (3.8.5)\n",
            "Collecting pycryptodomex~=3.8 (from blobfile->evals==1.0.3.post1)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->evals==1.0.3.post1) (1.26.16)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->evals==1.0.3.post1) (4.9.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->evals==1.0.3.post1) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->evals==1.0.3.post1)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->evals==1.0.3.post1)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->evals==1.0.3.post1) (2023.6.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->evals==1.0.3.post1) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->evals==1.0.3.post1) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->evals==1.0.3.post1) (2.0.19)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->evals==1.0.3.post1) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain->evals==1.0.3.post1)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain->evals==1.0.3.post1)\n",
            "  Downloading langsmith-0.0.18-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->evals==1.0.3.post1) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain->evals==1.0.3.post1)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->evals==1.0.3.post1) (8.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->evals==1.0.3.post1) (4.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (2.8.2)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy->evals==1.0.3.post1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->evals==1.0.3.post1) (2.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->evals==1.0.3.post1) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->evals==1.0.3.post1) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->evals==1.0.3.post1) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evals==1.0.3.post1) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->evals==1.0.3.post1) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->evals==1.0.3.post1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->evals==1.0.3.post1) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->evals==1.0.3.post1) (1.1.2)\n",
            "Collecting portalocker (from sacrebleu->evals==1.0.3.post1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->evals==1.0.3.post1) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->evals==1.0.3.post1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->evals==1.0.3.post1) (67.7.2)\n",
            "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (1.15.1)\n",
            "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /usr/lib/python3/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (3.4.8)\n",
            "Collecting oscrypto<2.0.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyOpenSSL<24.0.0,>=16.2.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt<3.0.0 in /usr/lib/python3/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2023.7.22)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.4.0)\n",
            "Collecting platformdirs<3.9.0,>=2.6.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading platformdirs-3.8.1-py3-none-any.whl (16 kB)\n",
            "Collecting tomlkit (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading tomlkit-0.12.1-py3-none-any.whl (37 kB)\n",
            "Collecting pyarrow>=8.0.0 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.2->evals==1.0.3.post1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.2->evals==1.0.3.post1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.2->evals==1.0.3.post1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.2->evals==1.0.3.post1) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.21)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->evals==1.0.3.post1)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->evals==1.0.3.post1)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting cryptography<42.0.0,>=3.1.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading cryptography-41.0.3-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->evals==1.0.3.post1) (2.0.2)\n",
            "Building wheels for collected packages: evals, fire, langdetect\n",
            "  Building editable for evals (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evals: filename=evals-1.0.3.post1-0.editable-py3-none-any.whl size=3699 sha256=be4cfb6721f2ce0245fb7e61c5581a4e2c8b2554f956dffe20c8e0ed91f98d10\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p0j9hm4g/wheels/81/f0/4a/034257e4ea0b6a82c749ffe52ef2691e7643ddf58d3c98d5b6\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=ac81f120fd37e2e0cc2a0dc908c3dc07363e4ca5cc811609544a287957ef883e\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=6ec3f2f8ebbe3b19a4a8d44cbd1e6734fa99cfce7b4c2066202369343a6ab9ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built evals fire langdetect\n",
            "Installing collected packages: types-PyYAML, asn1crypto, xxhash, tomlkit, setuptools-scm, pyzstd, pycryptodomex, pyarrow, portalocker, platformdirs, oscrypto, mypy-extensions, mock, marshmallow, lz4, langdetect, fire, dill, colorama, backoff, typing-inspect, sacrebleu, openapi-schema-pydantic, mypy, multiprocess, langsmith, huggingface-hub, cryptography, blobfile, pyOpenSSL, dataclasses-json, snowflake-connector-python, langchain, datasets, evals\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 3.9.1\n",
            "    Uninstalling platformdirs-3.9.1:\n",
            "      Successfully uninstalled platformdirs-3.9.1\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asn1crypto-1.5.1 backoff-2.2.1 blobfile-2.0.2 colorama-0.4.6 cryptography-41.0.3 dataclasses-json-0.5.14 datasets-2.14.3 dill-0.3.7 evals-1.0.3.post1 fire-0.5.0 huggingface-hub-0.16.4 langchain-0.0.251 langdetect-1.0.9 langsmith-0.0.18 lz4-4.3.2 marshmallow-3.20.1 mock-5.1.0 multiprocess-0.70.15 mypy-1.4.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 oscrypto-1.3.0 platformdirs-3.8.1 portalocker-2.7.0 pyOpenSSL-23.2.0 pyarrow-10.0.1 pycryptodomex-3.18.0 pyzstd-0.15.9 sacrebleu-2.3.1 setuptools-scm-7.1.0 snowflake-connector-python-3.1.0 tomlkit-0.12.1 types-PyYAML-6.0.12.11 typing-inspect-0.9.0 xxhash-3.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cryptography",
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# APIキー(※今回は、一時的な佐藤のAPI KEYで試してます別途、ご自身で設定してください)\n",
        "openai.api_key = \"sk-XXX\""
      ],
      "metadata": {
        "id": "adNxf7XVyU6j"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjrOolrtygKi",
        "outputId": "e5142f0a-045d-4d83-a855-7908bea63b03"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 60\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:29 docs\n",
            "drwxr-xr-x 9 root root 4096 Aug  4 09:00 evals\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:57 evals.egg-info\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:29 examples\n",
            "-rw-r--r-- 1 root root 1063 Aug  4 08:29 LICENSE\n",
            "-rw-r--r-- 1 root root   68 Aug  4 08:29 Makefile\n",
            "-rw-r--r-- 1 root root  136 Aug  4 08:29 MANIFEST.in\n",
            "-rw-r--r-- 1 root root 1014 Aug  4 08:29 mypy.ini\n",
            "-rw-r--r-- 1 root root  751 Aug  4 08:29 pyproject.toml\n",
            "-rw-r--r-- 1 root root 5704 Aug  4 08:29 README.md\n",
            "drwxr-xr-x 2 root root 4096 Aug  4 08:29 scripts\n",
            "-rw-r--r-- 1 root root  413 Aug  4 08:29 SECURITY.md\n",
            "drwxr-xr-x 3 root root 4096 Aug  4 08:29 tests\n",
            "drwxr-xr-x 3 root root 4096 Aug  4 08:29 typings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 修正中\n",
        "!oaieval gpt-3.5-turbo test-match"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wunwdzx3xWO7",
        "outputId": "2f0f751a-8d8f-4872-e399-c99f3b74881d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-08-04 09:08:17,779] [registry.py:270] Loading registry from /content/evals/evals/registry/evals\n",
            "[2023-08-04 09:08:18,497] [registry.py:270] Loading registry from /root/.evals/evals\n",
            "[2023-08-04 09:08:18,499] [oaieval.py:200] \u001b[1;35mRun started: 230804090818BVLI2TKZ\u001b[0m\n",
            "[2023-08-04 09:08:18,500] [eval.py:33] Evaluating 3 samples\n",
            "[2023-08-04 09:08:18,505] [eval.py:139] Running in threaded mode with 10 threads!\n",
            "  0% 0/3 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/oaieval\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/content/evals/evals/cli/oaieval.py\", line 257, in main\n",
            "    run(args)\n",
            "  File \"/content/evals/evals/cli/oaieval.py\", line 233, in run\n",
            "    result = eval.run(recorder)\n",
            "  File \"/content/evals/evals/elsuite/basic/match.py\", line 60, in run\n",
            "    self.eval_all_samples(recorder, samples)\n",
            "  File \"/content/evals/evals/eval.py\", line 141, in eval_all_samples\n",
            "    idx_and_result = list(tqdm(iter, total=len(work_items), disable=not show_progress))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1178, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 873, in next\n",
            "    raise value\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/content/evals/evals/eval.py\", line 132, in eval_sample\n",
            "    return idx, self.eval_sample(sample, rng)\n",
            "  File \"/content/evals/evals/elsuite/basic/match.py\", line 46, in eval_sample\n",
            "    result = self.completion_fn(\n",
            "  File \"/content/evals/evals/completion_fns/openai.py\", line 130, in __call__\n",
            "    result = openai_chat_completion_create_retrying(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/backoff/_sync.py\", line 105, in retry\n",
            "    ret = target(*args, **kwargs)\n",
            "  File \"/content/evals/evals/utils/api_utils.py\", line 69, in openai_chat_completion_create_retrying\n",
            "    result = request_with_timeout(openai.ChatCompletion.create, *args, **kwargs)\n",
            "  File \"/content/evals/evals/utils/api_utils.py\", line 46, in request_with_timeout\n",
            "    result = future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 149, in create\n",
            "    ) = cls.__prepare_create_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 106, in __prepare_create_request\n",
            "    requestor = api_requestor.APIRequestor(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 138, in __init__\n",
            "    self.api_key = key or util.default_api_key()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/util.py\", line 186, in default_api_key\n",
            "    raise openai.error.AuthenticationError(\n",
            "openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section2. ChatGPTにおける、OpenAIにおけるプロンプト\n",
        "『Section1-1. 明確な指示を書く』でみていきました。もうすこし詳しくみていきます。  \n",
        "\n",
        "ChatGPTについて基本的な知識を羅列します。  \n",
        "\n",
        "*   ChatGPTはOpenAI(オープンAI)という企業が開発した会話型のAIチャットボット\n",
        "*   他に画像が作れるAI、音楽が作れるAIがある中で、OpenAIは文章を作る文章生成AI\n",
        "*   英語だけでなく、日本語でも人間が作った文章と思うようなレベルの滑らかで自然な文章を生成できる\n",
        "\n",
        "ChatGPTというのは、あたかも知性を持ち、考えているような動作をしているように見えますが、実はそうではないです。\n",
        "\n",
        "**前に書かれている文章の続きを、確率的に有り得そうな単語を繋げてくれている**\n",
        "\n",
        "GPT-3では、45TB（テラバイト）の膨大なテキストデータに対して、いくつかの前処理を行って絞られた570GBのデータセットを使って学習されており、GPT-3.5においては数兆単語という膨大なボリュームデータを利用して学習され、それっぽい単語を繋ぎ合わせることで、会話を成立させています\n",
        "\n",
        "**数ある候補の中から、『それっぽいもの』を答えるのが、ChatGPT**\n",
        "\n"
      ],
      "metadata": {
        "id": "AJUb6ohg0Iva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Section2-1. ChatGPTから精度の良い応答を得るためには？\n",
        "**プロンプト**  \n",
        "望む結果を得るための指示のこと。『〇〇について、教えて』などのように入力する質問文を指します。\n",
        "\n",
        "このプロンプトによって、つまり、ユーザーが質問する内容や指示の仕方によってChatGPTから返ってくる応対の文章の質が変わってきます。これら工夫のことを、プロンプトエンジニアリングと言います。合図やことばという『刺激』をうまく与えることで、指示することで、反応によって相手をうまく動かすようなイメージになります。\n"
      ],
      "metadata": {
        "id": "ziQTTp_K9G3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプル\n",
        "messages = [] # 新しくリストを定義する\n",
        "max_messages = 10 # 最大メッセージ数を定義する\n",
        "\n",
        "print(\"AIの性格を決めて下さい\")\n",
        "\n",
        "AI_input = input(\"AI: \")\n",
        "\n",
        "# システムメッセージをmessagesリストに追加\n",
        "messages.append({\"role\": \"system\", \"content\": AI_input})"
      ],
      "metadata": {
        "id": "CBQuyYoAz_D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # ユーザーからの入力を取得する\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # endが入力された場合は、プログラムを終了する\n",
        "    if user_input == \"end\":\n",
        "        break\n",
        "\n",
        "    # メッセージを追加する\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # APIにユーザーからの入力を送信し、AIからの応答を取得する\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0301\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    # AIからの応答を取得する\n",
        "    ai_response = response['choices'][0]['message']['content']\n",
        "\n",
        "    # 応答を表示する\n",
        "    print(f\"AI: {ai_response}\")\n",
        "\n",
        "    # メッセージを追加する\n",
        "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "    # messagesリストの中身がmax_messagesを超えた場合、最初のuserとassistantの会話を削除する\n",
        "    if len(messages) > max_messages * 2 + 1:  # システムメッセージが含まれているため、+1します\n",
        "        messages.pop(1)  # システムメッセージの次のメッセージを削除\n",
        "        messages.pop(1)  # その後のassistantメッセージを削除\n",
        "\n",
        "    # !が入力された場合、messagesリストの中身を表示する\n",
        "    if user_input == \"!\":\n",
        "        print(\"messages:\", messages)"
      ],
      "metadata": {
        "id": "v0XOsH3l-hWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 次回"
      ],
      "metadata": {
        "id": "ZypcOUWk-hYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYh5jgMr-ha3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HKRXJEB-hc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}